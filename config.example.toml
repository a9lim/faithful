# Faithful Discord Bot Configuration
# Copy this file to config.toml and fill in your values.

[discord]
token = ""            # Required: your Discord bot token
admin_ids = []        # Required: list of Discord user IDs, e.g. [123456789, 987654321]

[backend]
# Options: openai, openai-compatible, ollama, gemini, anthropic
active = "openai-compatible"

# API key and model for the active LLM backend
api_key = ""
model = ""

# Optional provider-specific settings
# base_url = ""                            # Required for openai-compatible (e.g. "http://localhost:1234/v1")
# host = "http://localhost:11434"           # Ollama server address

[llm]
temperature = 1.0     # 0.0 to 2.0
max_tokens = 1024
sample_size = 300     # Example messages to include in system prompt

[behavior]
persona_name = "faithful"
reply_probability = 0.02      # 0.0 to 1.0 — chance to reply to random messages
reaction_probability = 0.05   # 0.0 to 1.0 — chance to react to messages without replying
debounce_delay = 3.0          # Seconds to wait before responding
conversation_expiry = 300.0   # Seconds before a conversation goes stale
max_context_messages = 20
enable_web_search = false     # LLM can search the web
enable_memory = false         # Per-user and per-channel memory

# Optional: custom system prompt template
# Available placeholders: {name}, {examples}, {memories}, {custom_emojis}
# system_prompt = "..."

[scheduler]
channels = []       # Channel IDs for unprompted messages
min_hours = 12
max_hours = 24
